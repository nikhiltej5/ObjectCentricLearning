{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d30462",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T15:28:33.117774Z",
     "iopub.status.busy": "2024-05-06T15:28:33.117485Z",
     "iopub.status.idle": "2024-05-06T15:28:54.455816Z",
     "shell.execute_reply": "2024-05-06T15:28:54.454707Z"
    },
    "papermill": {
     "duration": 21.346964,
     "end_time": "2024-05-06T15:28:54.458158",
     "exception": false,
     "start_time": "2024-05-06T15:28:33.111194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import sys\n",
    "import torch.cuda, torch.utils.data, torch.nn, torch.optim, torch\n",
    "import torchvision.transforms, torchvision.datasets.folder, torchvision.utils\n",
    "from sklearn.cluster import KMeans\n",
    "from cv2 import imread as img_read\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "import math\n",
    "\n",
    "!pip install einops\n",
    "sys.path.append('kaggle/input/clevertex/part2/part2')\n",
    "sys.path.append(os.path.abspath('../input/clevertex/part2/part2'))\n",
    "from vae_ import VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f8569d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T15:28:54.471275Z",
     "iopub.status.busy": "2024-05-06T15:28:54.470648Z",
     "iopub.status.idle": "2024-05-06T15:28:54.483584Z",
     "shell.execute_reply": "2024-05-06T15:28:54.482679Z"
    },
    "papermill": {
     "duration": 0.021577,
     "end_time": "2024-05-06T15:28:54.485488",
     "exception": false,
     "start_time": "2024-05-06T15:28:54.463911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Addresses\n",
    "\n",
    "class Address:\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Stores all the addresses used in project\n",
    "        '''\n",
    "        # Inputs\n",
    "        self.data = \"../input/clevertex/dataset/dataset\"\n",
    "        self.img_train = os.path.join(self.data, \"images/train\")\n",
    "        self.img_val = os.path.join(self.data, \"images/val\")\n",
    "        self.mask_train = os.path.join(self.data, \"masks/train\")\n",
    "        self.mask_val = os.path.join(self.data, \"masks/val\")\n",
    "\n",
    "        # Models\n",
    "        self.model = \"results/\"\n",
    "        self.slot_attention = os.path.join(self.model, \"slot_attention\")\n",
    "        self.vae_checkpoint = \"../input/clevertex/part2/part2/vae_checkpoint.pth\"\n",
    "        self.slot_diffusion = os.path.join(self.model, \"slot_diffusion\")\n",
    "        self.diff_checkpoint = \"../input/clevertex/best2.pth\"\n",
    "        self.slot_checkpoint = \"../input/clevertex/best1.pth\"\n",
    "\n",
    "        # Temp\n",
    "        self.temp = \"temp/\"\n",
    "\n",
    "    def create_dir(self, dir_list = None):\n",
    "        '''\n",
    "        Function to create directories in dir_list. If dir_list is None then create all directories of address.\n",
    "        '''\n",
    "        if dir_list == None:\n",
    "            dir_list = [self.model, self.temp, self.slot_attention, self.slot_diffusion]\n",
    "        for address in dir_list:\n",
    "            if not os.path.exists(address):\n",
    "                os.mkdir(address)\n",
    "\n",
    "    def _delete_folder_content(self, folder_addr):\n",
    "        '''\n",
    "        Deletes all the content of folder_addr\n",
    "        '''\n",
    "        if os.path.exists(folder_addr):\n",
    "            for file in os.listdir(folder_addr):\n",
    "                address = os.path.join(folder_addr, file)\n",
    "                if os.path.isdir(address):\n",
    "                    self._delete_folder_content(address)\n",
    "                    os.removedirs(address)\n",
    "                else:\n",
    "                    os.remove(address)\n",
    "\n",
    "    def clean(self, file_list = None):\n",
    "        '''\n",
    "        Deletes all the content in file_list\n",
    "        '''\n",
    "        if file_list == None:\n",
    "            file_list = [self.temp]\n",
    "        for address in file_list:\n",
    "            self._delete_folder_content(address)\n",
    "\n",
    "addr = Address()\n",
    "addr.clean()\n",
    "# addr.clean([addr.slot_attention])\n",
    "addr.create_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8192484",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T15:28:54.497469Z",
     "iopub.status.busy": "2024-05-06T15:28:54.497199Z",
     "iopub.status.idle": "2024-05-06T15:28:54.510640Z",
     "shell.execute_reply": "2024-05-06T15:28:54.509825Z"
    },
    "papermill": {
     "duration": 0.021743,
     "end_time": "2024-05-06T15:28:54.512562",
     "exception": false,
     "start_time": "2024-05-06T15:28:54.490819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HyperParameters:\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Stores all Hyperparameters used for training of model\n",
    "        '''\n",
    "        # Training\n",
    "        self.batch_size = 2\n",
    "        self.resolution = (128, 128)\n",
    "        self.num_epoch = 30\n",
    "        self.grad_clip = 1.0\n",
    "\n",
    "        # Data\n",
    "        self.num_train = 40000\n",
    "        self.num_val = 10000\n",
    "        self.train_step = self.num_epoch*(self.num_train//self.batch_size)\n",
    "        \n",
    "        # Learning Rate\n",
    "        self.lr = 2e-4\n",
    "        self.slot_lr = 2e-4\n",
    "        self.warmup_step = self.train_step//40\n",
    "        self.decay_step = self.train_step//2\n",
    "        self.decay_rate = 0.5\n",
    "\n",
    "        # Encoder\n",
    "        self.dim_input = 64\n",
    "        self.shift = 3\n",
    "        self.num_resblock = 1\n",
    "\n",
    "        # Slot Attention\n",
    "        self.dim_slot = 64\n",
    "        self.dim_projected = 64\n",
    "        self.dim_mlp_slot = 128\n",
    "        self.num_slot = 11\n",
    "        self.num_iter_slot = 3\n",
    "        self.epsilon = 1e-8\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder_channel = 64\n",
    "\n",
    "        # Evaluation\n",
    "        self.ari_batch_size = 32\n",
    "\n",
    "        # Diffusion\n",
    "        self.diffusion_time = 1000\n",
    "        self.beta1 = 0.0015\n",
    "        self.betaT = 0.0195\n",
    "        self.dim_time = 128\n",
    "        self.num_channel = 64\n",
    "        self.num_repeat = 6\n",
    "        self.dim_head = 32\n",
    "\n",
    "    def lr_schedule(self, step):\n",
    "        '''\n",
    "        Getting learning rate as function of train steps completed\n",
    "        '''\n",
    "        if step <= self.warmup_step:\n",
    "            return step/self.warmup_step\n",
    "        else:\n",
    "            return self.decay_rate**((step-self.warmup_step)/self.decay_step)\n",
    "\n",
    "    def create_report(self, addr):\n",
    "        with open(os.path.join(addr, 'param.txt'), 'w') as file:\n",
    "            file.writelines([\n",
    "                f'Training:',\n",
    "                f'\\n\\tBatch Size:       {self.batch_size}',\n",
    "                f'\\n\\tResolution:       {self.resolution}',\n",
    "                f'\\n\\tNum Epoch:        {self.num_epoch}',\n",
    "                f'\\n\\tGrad Clip:        {self.grad_clip}',\n",
    "                f'\\n\\nData:',  \n",
    "                f'\\n\\tNum Train:        {self.num_train}',\n",
    "                f'\\n\\tNum Val:          {self.num_val}',\n",
    "                f'\\n\\tTrain Step:       {self.train_step}',\n",
    "                f'\\n\\nLearning Rate:',  \n",
    "                f'\\n\\tlr:               {self.lr}',\n",
    "                f'\\n\\tslot_lr:          {self.slot_lr}',\n",
    "                f'\\n\\tWarmup Step:      {self.warmup_step}',\n",
    "                f'\\n\\tDecay Step:       {self.decay_step}',\n",
    "                f'\\n\\tDecay Rate:       {self.decay_rate}',\n",
    "                f'\\n\\nEncoder:',  \n",
    "                f'\\n\\tDim Input:        {self.dim_input}',\n",
    "                f'\\n\\tShift:            {self.shift}',\n",
    "                f'\\n\\tNum Resblock:     {self.num_resblock}',\n",
    "                f'\\n\\nSlot Attention:',\n",
    "                f'\\n\\tDim Slot:         {self.dim_slot}',\n",
    "                f'\\n\\tDim Projected:    {self.dim_projected}',\n",
    "                f'\\n\\tDim MLP slot:     {self.dim_mlp_slot}',\n",
    "                f'\\n\\tNum Slot:         {self.num_slot}',\n",
    "                f'\\n\\tNum Iter Slot:    {self.num_iter_slot}',\n",
    "                f'\\n\\tEpsilon:          {self.epsilon}',\n",
    "                f'\\n\\nDecoder:',  \n",
    "                f'\\n\\tDecoder Channel:  {self.decoder_channel}',\n",
    "                f'\\n\\nEvaluation:',\n",
    "                f'\\n\\tARI Batch Size:   {self.ari_batch_size}',\n",
    "                f'\\n\\nDiffusion:',\n",
    "                f'\\n\\tDiffusion Time:   {self.diffusion_time}',\n",
    "                f'\\n\\tBeta_1:           {self.beta1}',\n",
    "                f'\\n\\tBeta_T:           {self.betaT}',\n",
    "                f'\\n\\tDim Time:         {self.dim_time}',\n",
    "                f'\\n\\tNum Channel:      {self.num_channel}',\n",
    "                f'\\n\\tNum Repeat:       {self.num_repeat}',\n",
    "                f'\\n\\tDim Head:         {self.dim_head}'\n",
    "            ])\n",
    "\n",
    "param = HyperParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01389b32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T15:28:54.524220Z",
     "iopub.status.busy": "2024-05-06T15:28:54.523739Z",
     "iopub.status.idle": "2024-05-06T15:28:54.575502Z",
     "shell.execute_reply": "2024-05-06T15:28:54.574377Z"
    },
    "papermill": {
     "duration": 0.060011,
     "end_time": "2024-05-06T15:28:54.577746",
     "exception": false,
     "start_time": "2024-05-06T15:28:54.517735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Random Seed and CUDA\n",
    "\n",
    "random_seed = 68\n",
    "device = \"cpu\"\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    device = \"cuda\"\n",
    "print(f\"Working with device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c972248",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T15:28:54.590234Z",
     "iopub.status.busy": "2024-05-06T15:28:54.589922Z",
     "iopub.status.idle": "2024-05-06T15:28:56.643745Z",
     "shell.execute_reply": "2024-05-06T15:28:56.642958Z"
    },
    "papermill": {
     "duration": 2.062627,
     "end_time": "2024-05-06T15:28:56.645995",
     "exception": false,
     "start_time": "2024-05-06T15:28:54.583368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset\n",
    "\n",
    "class DataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, resolution, address_img, address_mask = None):\n",
    "        self.address_img = address_img\n",
    "        self.address_mask = address_mask\n",
    "        self.img_list = sorted(os.listdir(self.address_img))\n",
    "        if self.address_mask is not None:\n",
    "            self.mask_list = sorted(os.listdir(self.address_mask))\n",
    "            self.mask_dict = {(0, 0, 0): 0}\n",
    "            self.num_category = 1\n",
    "        self.transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                                         torchvision.transforms.Resize(resolution, antialias=False)])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_addr = os.path.join(self.address_img, self.img_list[idx])\n",
    "        img = torchvision.datasets.folder.default_loader(img_addr)\n",
    "\n",
    "        if self.address_mask is not None:\n",
    "            mask_addr = os.path.join(self.address_mask, self.mask_list[idx])\n",
    "            mask = img_read(mask_addr)\n",
    "            new_mask = torch.zeros(mask.shape[0], mask.shape[1], dtype=torch.long)\n",
    "            for i in range(mask.shape[0]):\n",
    "                for j in range(mask.shape[1]):\n",
    "                    color = tuple(mask[i, j, :])\n",
    "                    if color not in self.mask_dict:\n",
    "                        self.mask_dict[color] = self.num_category\n",
    "                        self.num_category += 1\n",
    "                    new_mask[i,j] = self.mask_dict[color]\n",
    "\n",
    "            return {\n",
    "                'img': self.transform(img).to(torch.float),\n",
    "                'mask': new_mask\n",
    "            }\n",
    "        \n",
    "        return self.transform(img).to(torch.float)\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, address: Address, param: HyperParameters, device = device):\n",
    "        '''\n",
    "        Creates DataLoader and DataSet for both train and val split\n",
    "        '''\n",
    "        self.address = address\n",
    "        self.device = device\n",
    "\n",
    "        # Dataset for training\n",
    "        self.dataset_train_without_mask = DataSet(param.resolution, address.img_train)\n",
    "        self.dataset_val_without_mask = DataSet(param.resolution, address.img_val)\n",
    "\n",
    "        # DataLoader for training\n",
    "        self.loader_train_without_mask = torch.utils.data.DataLoader(self.dataset_train_without_mask,\n",
    "                                                                     batch_size=param.batch_size,\n",
    "                                                                     shuffle=True)\n",
    "        self.loader_val_without_mask = torch.utils.data.DataLoader(self.dataset_val_without_mask,\n",
    "                                                                   batch_size=param.batch_size,\n",
    "                                                                   shuffle=False)\n",
    "\n",
    "        # Dataset for evaluation\n",
    "        self.dataset_train_with_mask = DataSet(param.resolution, address.img_train, address.mask_train)\n",
    "        self.dataset_val_with_mask = DataSet(param.resolution, address.img_val, address.mask_val)\n",
    "\n",
    "        # DataLoader for evaluation\n",
    "        self.loader_train_with_mask = torch.utils.data.DataLoader(self.dataset_train_with_mask,\n",
    "                                                                  batch_size=param.ari_batch_size,\n",
    "                                                                  shuffle=False,\n",
    "                                                                  collate_fn=self.collate,\n",
    "                                                                  num_workers=4)\n",
    "        self.loader_val_with_mask = torch.utils.data.DataLoader(self.dataset_val_with_mask,\n",
    "                                                                batch_size=param.ari_batch_size,\n",
    "                                                                shuffle=False,\n",
    "                                                                collate_fn=self.collate)\n",
    "\n",
    "    def collate(self, batch):\n",
    "        img = [elem['img'] for elem in batch]\n",
    "        mask = [elem['mask'] for elem in batch]\n",
    "\n",
    "        return {\n",
    "            'img': torch.stack(img),\n",
    "            'mask': torch.stack(mask)\n",
    "        }\n",
    "\n",
    "data = Data(addr, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f72c58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T15:28:56.660406Z",
     "iopub.status.busy": "2024-05-06T15:28:56.660073Z",
     "iopub.status.idle": "2024-05-06T15:28:56.779921Z",
     "shell.execute_reply": "2024-05-06T15:28:56.779174Z"
    },
    "papermill": {
     "duration": 0.128959,
     "end_time": "2024-05-06T15:28:56.781999",
     "exception": false,
     "start_time": "2024-05-06T15:28:56.653040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Models\n",
    "\n",
    "def create_grid(resolution):\n",
    "    '''\n",
    "    Creates the grid of size resolution with 4 channels. Each channel representing gradient in [0, 1] for one of the four direction.\n",
    "    '''\n",
    "    x_grad = np.linspace(0, 1, resolution[1])\n",
    "    y_grad = np.linspace(0, 1, resolution[0])\n",
    "    grid = np.meshgrid(y_grad, x_grad, indexing='ij')\n",
    "    grid = np.stack(grid, axis = -1)\n",
    "    grid = np.concatenate([grid, 1-grid], axis=-1)\n",
    "    grid = np.expand_dims(grid, axis=0)\n",
    "    return torch.tensor(grid, dtype=torch.float, requires_grad=False)\n",
    "\n",
    "class ResBlock(torch.nn.Module):\n",
    "    def __init__(self, num_channel, kernel_size=5, stride=1, padding='same'):\n",
    "        '''\n",
    "        Initializes a Resnet Block with one convolution layer having ReLU activation\n",
    "        '''\n",
    "        super(ResBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(num_channel, num_channel, kernel_size, stride=stride, padding=padding, dtype=torch.float)\n",
    "        self.norm1 = torch.nn.InstanceNorm2d(num_channel)\n",
    "        self.activation1 = torch.nn.ReLU()\n",
    "\n",
    "        self.conv2 = torch.nn.Conv2d(num_channel, num_channel, kernel_size, stride=1, padding='same', dtype=torch.float)\n",
    "        self.norm2 = torch.nn.InstanceNorm2d(num_channel)\n",
    "        self.activation2 = torch.nn.ReLU()\n",
    "\n",
    "        self.project = True if (stride != 1) else False\n",
    "        if self.project:\n",
    "            self.conv_project = torch.nn.Conv2d(num_channel, num_channel, kernel_size, stride=stride, padding=padding, dtype=torch.float)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "\n",
    "        # First convolution\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.activation1(x)\n",
    "\n",
    "        # Second Convolution\n",
    "        x = self.conv2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = x + (self.conv_project(res) if self.project else res)\n",
    "        x = self.activation2(x)\n",
    "        return x\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, num_channel, shift, num_resblock=1, device=device):\n",
    "        '''\n",
    "        Encodes input image into feature vectors\n",
    "        '''\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.num_channel = num_channel\n",
    "        self.shift = shift\n",
    "\n",
    "        # CNN backbone of Encoder    \n",
    "        cnn = [torch.nn.Conv2d(3, num_channel, 5, stride=1, padding='same', dtype=torch.float), torch.nn.ReLU()]\n",
    "        for _ in range(shift):\n",
    "            cnn.append(ResBlock(num_channel, 5, stride=2, padding=2))\n",
    "            for i in range(num_resblock):\n",
    "                cnn.append(ResBlock(num_channel, 5, stride=1, padding='same'))\n",
    "        cnn.append(ResBlock(num_channel, 5, stride=1, padding='same'))\n",
    "        self.cnn = torch.nn.Sequential(*cnn)\n",
    "        \n",
    "        # Positional Embedding\n",
    "        self.register_buffer('grid', None)\n",
    "        self.embed = torch.nn.Linear(4, num_channel, dtype=torch.float)\n",
    "\n",
    "        # Flatten\n",
    "        self.flatten = torch.nn.Flatten(start_dim=1, end_dim=2)\n",
    "\n",
    "        # Layer Norm\n",
    "        self.layer_norm = torch.nn.LayerNorm(num_channel, dtype=torch.float)\n",
    "\n",
    "        # MLP\n",
    "        self.mlp = torch.nn.Sequential(torch.nn.Linear(num_channel, num_channel, dtype=torch.float),\n",
    "                                       torch.nn.ReLU(),\n",
    "                                       torch.nn.Linear(num_channel, num_channel, dtype=torch.float))\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.cnn(x)     # CNN\n",
    "\n",
    "        x = x.permute((0, 2, 3, 1))     # Permuting Channel axis at the end\n",
    "\n",
    "        if self.grid is None:\n",
    "            self.grid = create_grid(x.shape[1:3]).to(self.device)\n",
    "        x = x + self.embed(self.grid)   # Positional Embedding\n",
    "\n",
    "        x = self.flatten(x)     # Flatten into feature vector\n",
    "\n",
    "        x = self.layer_norm(x)  # Layer Normalization\n",
    "\n",
    "        x = self.mlp(x)     # MLP\n",
    "\n",
    "        return x\n",
    "\n",
    "class SlotAttention(torch.nn.Module):\n",
    "    def __init__(self, dim_input, dim_slot, dim_projected, dim_mlp, num_slot, num_iter, epsilon, device=device):\n",
    "        '''\n",
    "        Implementes Slot Attention\n",
    "        '''\n",
    "        super(SlotAttention, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.dim_input = dim_input\n",
    "        self.dim_slot = dim_slot\n",
    "        self.dim_projected = dim_projected\n",
    "        self.dim_mlp = dim_mlp\n",
    "        self.num_slot = num_slot\n",
    "        self.num_iter = num_iter\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        # Layer Norm\n",
    "        self.layer_norm_inp = torch.nn.LayerNorm(dim_input, dtype=torch.float)\n",
    "        self.layer_norm_slot = torch.nn.LayerNorm(dim_slot, dtype=torch.float)\n",
    "\n",
    "        # Slot Initialization Parameters\n",
    "        self.slots = torch.nn.Parameter(torch.randn(1, self.num_slot, self.dim_slot, dtype=torch.float))\n",
    "        # self.mean_slot = torch.nn.Parameter(torch.zeros(1, 1, self.dim_slot, dtype=torch.float))\n",
    "        # self.log_std_slot = torch.nn.Parameter(torch.zeros(1, 1, self.dim_slot, dtype=torch.float))\n",
    "        # torch.nn.init.xavier_uniform_(self.mean_slot)\n",
    "        # torch.nn.init.xavier_uniform_(self.log_std_slot)\n",
    "\n",
    "        # Projection matrix\n",
    "        self.project_key = torch.nn.Linear(self.dim_input, self.dim_projected, bias=False, dtype=torch.float)\n",
    "        self.project_value = torch.nn.Linear(self.dim_input, self.dim_projected, bias=False, dtype=torch.float)\n",
    "        self.project_query = torch.nn.Linear(self.dim_slot, self.dim_projected, bias=False, dtype=torch.float)\n",
    "\n",
    "        # Slot update\n",
    "        self.gru = torch.nn.GRUCell(self.dim_projected, self.dim_slot)\n",
    "        self.mlp = torch.nn.Sequential(torch.nn.Linear(self.dim_slot, self.dim_mlp),\n",
    "                                       torch.nn.ReLU(),\n",
    "                                       torch.nn.Linear(self.dim_mlp, self.dim_slot))\n",
    "\n",
    "    def forward(self, x, ret_attn = False):\n",
    "        x = self.layer_norm_inp(x)          # Layer Normalization\n",
    "\n",
    "        slots = torch.tile(self.slots, dims = (x.shape[0], 1, 1))                  # Initializing Slot\n",
    "        # slots = self.mean_slot + torch.exp(self.log_std_slot)*torch.randn((x.shape[0], self.num_slot, self.dim_slot), device=self.device)      # Initializing slot\n",
    "        attn_arr = []\n",
    "\n",
    "        for t in range(self.num_iter):\n",
    "            slots_prev = slots\n",
    "            slots = self.layer_norm_slot(slots)         # Layer Normalization\n",
    "\n",
    "            # Computing Attention\n",
    "            attn = torch.matmul(self.project_key(x), self.project_query(slots).permute(0, 2, 1))   # Dot product of key and query\n",
    "            attn /= np.sqrt(self.dim_projected)                                                    # Setting SoftMax temperature\n",
    "            attn = torch.nn.functional.softmax(attn, dim=-1) + self.epsilon                        # Softmax with numerical stability\n",
    "            attn_arr.append(attn)\n",
    "\n",
    "            # Updating Slot\n",
    "            weights = attn/torch.sum(attn, dim=1, keepdim=True)                         # Calculating weights for update\n",
    "            updates = torch.bmm(weights.permute(0, 2, 1), self.project_value(x))        # Update array\n",
    "            slots = self.gru(updates.reshape(-1, self.dim_projected), slots_prev.reshape(-1, self.dim_slot))    # GRU update\n",
    "            slots = slots.reshape(-1, self.num_slot, self.dim_slot)\n",
    "            slots = slots + self.mlp(slots)                                                    # Residual MLP update\n",
    "        \n",
    "        if ret_attn:\n",
    "            return slots, torch.stack(attn_arr).permute(1, 0, 2, 3)\n",
    "        return slots\n",
    "\n",
    "class SBDecoder(torch.nn.Module):\n",
    "    def __init__(self, num_slot, dim_slot, resolution, num_channel, device=device):\n",
    "        '''\n",
    "        Implements Spatial Broadcast Decoder\n",
    "        '''\n",
    "        super(SBDecoder, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.num_slot = num_slot\n",
    "        self.dim_slot = dim_slot\n",
    "        self.resolution = resolution\n",
    "        self.num_channel = num_channel\n",
    "\n",
    "        # Grid for spatial feature\n",
    "        self.register_buffer('grid', 2*create_grid(resolution).permute(0, 3, 1, 2)[:, :2, :, :]-1)\n",
    "\n",
    "        # CNN Decoder\n",
    "        self.cnn = torch.nn.Sequential(torch.nn.Conv2d(2+dim_slot, num_channel, 5, stride=1, padding='same', dtype=torch.float),\n",
    "                                       torch.nn.ReLU(),\n",
    "                                       torch.nn.Conv2d(num_channel, num_channel, 5, stride=1, padding='same', dtype=torch.float),\n",
    "                                       torch.nn.ReLU(),\n",
    "                                       torch.nn.Conv2d(num_channel, 4, 5, stride=1, padding='same', dtype=torch.float))\n",
    "\n",
    "    def forward(self, slots):\n",
    "        x = slots.reshape((-1, self.dim_slot, 1, 1))\n",
    "        \n",
    "        # Creating tiled latents\n",
    "        x = torch.tile(x, (1, 1, self.resolution[0], self.resolution[1]))\n",
    "        x = torch.concat([x, torch.tile(self.grid, (x.shape[0], 1, 1, 1))], dim=1)\n",
    "\n",
    "        # Decoding\n",
    "        x = self.cnn(x)\n",
    "\n",
    "        # Unstack and Split\n",
    "        x = x.reshape(-1, self.num_slot, 4, self.resolution[0], self.resolution[1])\n",
    "        img, mask = torch.split(x, [3, 1], dim=2)\n",
    "\n",
    "        # Reconstructing Image\n",
    "        mask = torch.nn.functional.softmax(mask, dim=1)\n",
    "        recon_img = torch.sum(img*mask, dim=1)\n",
    "        \n",
    "        return recon_img, img, mask.squeeze(2), slots\n",
    "\n",
    "class ObjectDiscovery(torch.nn.Module):\n",
    "    def __init__(self, param: HyperParameters, device=device):\n",
    "        '''\n",
    "        Architecture enclosing encoder, slot attention, spatial broadcast decoder for object discovery task\n",
    "        '''\n",
    "        super(ObjectDiscovery, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.encoder = Encoder(param.dim_input, param.shift, device=device)\n",
    "        self.slot_attention = SlotAttention(param.dim_input,\n",
    "                                            param.dim_slot,\n",
    "                                            param.dim_projected,\n",
    "                                            param.dim_mlp_slot,\n",
    "                                            param.num_slot,\n",
    "                                            param.num_iter_slot,\n",
    "                                            param.epsilon,\n",
    "                                            device=device)\n",
    "        self.decoder = SBDecoder(param.num_slot,\n",
    "                                 param.dim_slot,\n",
    "                                 param.resolution,\n",
    "                                 param.decoder_channel,\n",
    "                                 device=device)\n",
    "    \n",
    "    def forward(self, x, slot_only = False, attn=False):\n",
    "        x = self.encoder(x)\n",
    "        if attn:\n",
    "            x, attn_map = self.slot_attention(x, ret_attn = True)\n",
    "            return attn_map\n",
    "        x = self.slot_attention(x)\n",
    "        if slot_only:\n",
    "            return x\n",
    "        return self.decoder(x)\n",
    "\n",
    "class ResBlockUNET(torch.nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, dim_time, mode, kernel_size = 5, num_grp = 4):\n",
    "        super(ResBlockUNET, self).__init__()\n",
    "\n",
    "        self.mode = mode\n",
    "\n",
    "        # Block corresponding to input for various uses of res block\n",
    "        if mode == 'down':\n",
    "            self.inp = torch.nn.Sequential(\n",
    "                torch.nn.GroupNorm(num_grp, in_channel),\n",
    "                torch.nn.SiLU(),\n",
    "                torch.nn.AvgPool2d(2, 2)\n",
    "            )\n",
    "        elif mode == 'up':\n",
    "            self.inp = torch.nn.Sequential(\n",
    "                torch.nn.GroupNorm(num_grp, in_channel),\n",
    "                torch.nn.SiLU()\n",
    "            )\n",
    "        elif mode == 'same':\n",
    "            self.inp = torch.nn.Sequential(\n",
    "                torch.nn.GroupNorm(num_grp, in_channel),\n",
    "                torch.nn.SiLU(),\n",
    "                torch.nn.Conv2d(in_channel, in_channel, kernel_size, padding='same')\n",
    "            )\n",
    "        else:\n",
    "            raise Exception(\"No such mode\")\n",
    "\n",
    "        # Transforming time embedding to channel dimension\n",
    "        self.time = torch.nn.Sequential(\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(dim_time, in_channel)\n",
    "        )\n",
    "\n",
    "        # Layer for output generation with shortcut connection\n",
    "        self.out = torch.nn.Sequential(\n",
    "            torch.nn.GroupNorm(num_grp, in_channel),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.Conv2d(in_channel, out_channel, kernel_size, padding='same')\n",
    "        )\n",
    "\n",
    "        self.project = None\n",
    "        if in_channel != out_channel:\n",
    "            self.project = torch.nn.Conv2d(in_channel, out_channel, kernel_size, padding='same')\n",
    "\n",
    "    def forward(self, inp, time_emb):\n",
    "        inp_processed = self.inp(inp)\n",
    "        if self.mode == 'up':\n",
    "            inp_processed = torch.nn.functional.interpolate(inp_processed, scale_factor=2)\n",
    "        time_processed = self.time(time_emb).unsqueeze(-1).unsqueeze(-1)\n",
    "        x = inp_processed + time_processed\n",
    "        if self.project is None:\n",
    "            out = x + self.out(x)\n",
    "        else:\n",
    "            out = self.project(x) + self.out(x)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(self, dim_x, dim_query, dim_attention, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "\n",
    "        self.dim_attention = dim_attention\n",
    "        self.num_head = num_heads\n",
    "        self.query = torch.nn.Linear(dim_query, dim_attention, bias=False)\n",
    "        self.attention = torch.nn.MultiheadAttention(dim_attention, num_heads, kdim=dim_x, vdim=dim_x)\n",
    "    \n",
    "    def forward(self, x, query):\n",
    "        return self.attention.forward(self.query(query), x, x, need_weights=False)[0]\n",
    "\n",
    "class TransformerBlock(torch.nn.Module):\n",
    "    def __init__(self, num_repeat, dim_head, dim_slot, in_channel, device=device, num_grp = 4):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "\n",
    "        self.num_repeat = num_repeat\n",
    "        self.dim_head = dim_head\n",
    "        self.in_channel = in_channel\n",
    "        self.dim_slot = dim_slot\n",
    "        self.device = device\n",
    "\n",
    "        self.norm1 = torch.nn.GroupNorm(num_grp, in_channel)\n",
    "        self.conv1 = torch.nn.Conv2d(in_channel, in_channel, 1)\n",
    "\n",
    "        self.self_attention = torch.nn.ModuleList([torch.nn.MultiheadAttention(in_channel, in_channel//dim_head, batch_first=True) for i in range(num_repeat)])\n",
    "        self.norm2 = torch.nn.ModuleList([torch.nn.LayerNorm(self.in_channel) for i in range(num_repeat)])\n",
    "\n",
    "        self.cross_attention = torch.nn.ModuleList([torch.nn.MultiheadAttention(in_channel, in_channel//dim_head, kdim=dim_slot, vdim=dim_slot, batch_first=True) for i in range(num_repeat)])\n",
    "        self.norm3 = torch.nn.ModuleList([torch.nn.LayerNorm(self.in_channel) for i in range(num_repeat)])\n",
    "\n",
    "        self.mlp = torch.nn.ModuleList([torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_channel, in_channel),\n",
    "            torch.nn.LayerNorm(self.in_channel)\n",
    "        ) for i in range(num_repeat)])\n",
    "\n",
    "        self.conv2 = torch.nn.Conv2d(in_channel, in_channel, 1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, slots):\n",
    "        x = self.norm1(x)\n",
    "        x = self.conv1(x)\n",
    "        B, C, H, W = x.shape\n",
    "        x = x.reshape((B, C, H*W)).permute(0, 2, 1)\n",
    "        for i in range(self.num_repeat):\n",
    "            x = x + self.norm2[i](self.self_attention[i](x, x, x, need_weights=False)[0])\n",
    "            x = x + self.norm3[i](self.cross_attention[i](x, slots, slots, need_weights=False)[0])\n",
    "            x = x + self.mlp[i](x)\n",
    "        x = x.permute(0, 2, 1).reshape((B, C, H, W))\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "class UNET(torch.nn.Module):\n",
    "    def __init__(self, num_channel, dim_time, num_repeat, dim_head, dim_slot):\n",
    "        super(UNET, self).__init__()\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(3, num_channel, 5, padding='same')\n",
    "\n",
    "        self.r1 = ResBlockUNET(num_channel, num_channel, dim_time, mode = 'same')\n",
    "        self.r2 = ResBlockUNET(num_channel, num_channel, dim_time, mode = 'same')\n",
    "        self.r3 = ResBlockUNET(num_channel, 2*num_channel, dim_time, mode = 'same')\n",
    "        self.r4 = ResBlockUNET(2*num_channel, 2*num_channel, dim_time, mode = 'same')\n",
    "        self.r5 = ResBlockUNET(2*num_channel, 3*num_channel, dim_time, mode = 'same')\n",
    "        self.r6 = ResBlockUNET(3*num_channel, 3*num_channel, dim_time, mode = 'same')\n",
    "        self.r7 = ResBlockUNET(3*num_channel, 4*num_channel, dim_time, mode = 'same')\n",
    "        self.r8 = ResBlockUNET(4*num_channel, 4*num_channel, dim_time, mode = 'same')\n",
    "        self.r9 = ResBlockUNET(4*num_channel, 4*num_channel, dim_time, mode = 'same')\n",
    "        self.r10 = ResBlockUNET(4*num_channel, 4*num_channel, dim_time, mode = 'same')\n",
    "        self.r11 = ResBlockUNET(8*num_channel, 4*num_channel, dim_time, mode = 'same')\n",
    "        self.r12 = ResBlockUNET(8*num_channel, 4*num_channel, dim_time, mode = 'same')\n",
    "        self.r13 = ResBlockUNET(7*num_channel, 4*num_channel, dim_time, mode = 'same')\n",
    "        self.r14 = ResBlockUNET(7*num_channel, 3*num_channel, dim_time, mode = 'same')\n",
    "        self.r15 = ResBlockUNET(6*num_channel, 3*num_channel, dim_time, mode = 'same')\n",
    "        self.r15 = ResBlockUNET(6*num_channel, 3*num_channel, dim_time, mode = 'same')\n",
    "        self.r16 = ResBlockUNET(5*num_channel, 3*num_channel, dim_time, mode = 'same')\n",
    "        self.r17 = ResBlockUNET(5*num_channel, 2*num_channel, dim_time, mode = 'same')\n",
    "        self.r18 = ResBlockUNET(4*num_channel, 2*num_channel, dim_time, mode = 'same')\n",
    "        self.r19 = ResBlockUNET(3*num_channel, 2*num_channel, dim_time, mode = 'same')\n",
    "        self.r20 = ResBlockUNET(3*num_channel, num_channel, dim_time, mode = 'same')\n",
    "        self.r21 = ResBlockUNET(2*num_channel, num_channel, dim_time, mode = 'same')\n",
    "        self.r22 = ResBlockUNET(2*num_channel, num_channel, dim_time, mode = 'same')\n",
    "\n",
    "        self.d1 = ResBlockUNET(num_channel, num_channel, dim_time, mode = 'down')\n",
    "        self.d2 = ResBlockUNET(2*num_channel, 2*num_channel, dim_time, mode = 'down')\n",
    "        self.d3 = ResBlockUNET(3*num_channel, 3*num_channel, dim_time, mode = 'down')\n",
    "\n",
    "        self.u1 = ResBlockUNET(4*num_channel, 4*num_channel, dim_time, mode = 'up')\n",
    "        self.u2 = ResBlockUNET(3*num_channel, 3*num_channel, dim_time, mode = 'up')\n",
    "        self.u3 = ResBlockUNET(2*num_channel, 2*num_channel, dim_time, mode = 'up')\n",
    "\n",
    "        self.t1 = TransformerBlock(num_repeat, dim_head, dim_slot, 2*num_channel)\n",
    "        self.t2 = TransformerBlock(num_repeat, dim_head, dim_slot, 2*num_channel)\n",
    "        self.t3 = TransformerBlock(num_repeat, dim_head, dim_slot, 3*num_channel)\n",
    "        self.t4 = TransformerBlock(num_repeat, dim_head, dim_slot, 3*num_channel)\n",
    "        self.t5 = TransformerBlock(num_repeat, dim_head, dim_slot, 4*num_channel)\n",
    "        self.t6 = TransformerBlock(num_repeat, dim_head, dim_slot, 4*num_channel)\n",
    "        self.t7 = TransformerBlock(num_repeat, dim_head, dim_slot, 4*num_channel)\n",
    "        self.t8 = TransformerBlock(num_repeat, dim_head, dim_slot, 4*num_channel)\n",
    "        self.t9 = TransformerBlock(num_repeat, dim_head, dim_slot, 4*num_channel)\n",
    "        self.t10 = TransformerBlock(num_repeat, dim_head, dim_slot, 4*num_channel)\n",
    "        self.t11 = TransformerBlock(num_repeat, dim_head, dim_slot, 3*num_channel)\n",
    "        self.t12 = TransformerBlock(num_repeat, dim_head, dim_slot, 3*num_channel)\n",
    "        self.t13 = TransformerBlock(num_repeat, dim_head, dim_slot, 3*num_channel)\n",
    "        self.t14 = TransformerBlock(num_repeat, dim_head, dim_slot, 2*num_channel)\n",
    "        self.t15 = TransformerBlock(num_repeat, dim_head, dim_slot, 2*num_channel)\n",
    "        self.t16 = TransformerBlock(num_repeat, dim_head, dim_slot, 2*num_channel)\n",
    "\n",
    "        self.norm = torch.nn.GroupNorm(4, num_channel)\n",
    "        self.conv2 = torch.nn.Conv2d(num_channel, 3, 5, padding='same')\n",
    "\n",
    "    def forward(self, x, slots, time_emb):\n",
    "        # Down Sample\n",
    "        x_conv = self.conv1(x)\n",
    "        x_r1 = self.r1(x_conv, time_emb)\n",
    "        x_r2 = self.r2(x_r1, time_emb)\n",
    "        x_d1 = self.d1(x_r2, time_emb)\n",
    "        x_r3 = self.r3(x_d1, time_emb)\n",
    "        x_t1 = self.t1(x_r3, slots)\n",
    "        x_r4 = self.r4(x_t1, time_emb)\n",
    "        x_t2 = self.t2(x_r4, slots)\n",
    "        x_d2 = self.d2(x_t2, time_emb)\n",
    "        x_r5 = self.r5(x_d2, time_emb)\n",
    "        x_t3 = self.t3(x_r5, slots)\n",
    "        x_r6 = self.r6(x_t3, time_emb)\n",
    "        x_t4 = self.t4(x_r6, slots)\n",
    "        x_d3 = self.d3(x_t4, time_emb)\n",
    "        x_r7 = self.r7(x_d3, time_emb)\n",
    "        x_t5 = self.t5(x_r7, slots)\n",
    "        x_r8 = self.r8(x_t5, time_emb)\n",
    "        x_t6 = self.t6(x_r8, slots)\n",
    "\n",
    "        # Middle\n",
    "        x = self.r9(x_t6, time_emb)\n",
    "        x = self.t7(x, slots)\n",
    "        x = self.r10(x, time_emb)\n",
    "\n",
    "        # UpSampling\n",
    "        x = self.r11(torch.concat((x_t6, x), dim=1), time_emb)\n",
    "        x = self.t8(x, slots)\n",
    "        x = self.r12(torch.concat((x_t5, x), dim=1), time_emb)\n",
    "        x = self.t9(x, slots)\n",
    "        x = self.r13(torch.concat((x_d3, x), dim=1), time_emb)\n",
    "        x = self.t10(x, slots)\n",
    "        x = self.u1(x, time_emb)\n",
    "        x = self.r14(torch.concat((x_t4, x), dim=1), time_emb)\n",
    "        x = self.t11(x, slots)\n",
    "        x = self.r15(torch.concat((x_t3, x), dim=1), time_emb)\n",
    "        x = self.t12(x, slots)\n",
    "        x = self.r16(torch.concat((x_d2, x), dim=1), time_emb)\n",
    "        x = self.t13(x, slots)\n",
    "        x = self.u2(x, time_emb)\n",
    "        x = self.r17(torch.concat((x_t2, x), dim=1), time_emb)\n",
    "        x = self.t14(x, slots)\n",
    "        x = self.r18(torch.concat((x_t1, x), dim=1), time_emb)\n",
    "        x = self.t15(x, slots)\n",
    "        x = self.r19(torch.concat((x_d1, x), dim=1), time_emb)\n",
    "        x = self.t16(x, slots)\n",
    "        x = self.u3(x, time_emb)\n",
    "        x = self.r20(torch.concat((x_r2, x), dim=1), time_emb)\n",
    "        x = self.r21(torch.concat((x_r1, x), dim=1), time_emb)\n",
    "        x = self.r22(torch.concat((x_conv, x), dim=1), time_emb)\n",
    "        x = self.norm(x)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class LatentDefusionDecoder(torch.nn.Module):\n",
    "    def __init__(self, dim_time, diffusion_time, num_channel, num_repeat, dim_slot, dim_head):\n",
    "        super(LatentDefusionDecoder, self).__init__()\n",
    "\n",
    "        self.dim_time = dim_time\n",
    "        self.diffusion_time = diffusion_time\n",
    "        self.register_buffer('time_embed', self.time_embedding())\n",
    "\n",
    "        self.model = UNET(num_channel, dim_time, num_repeat, dim_head, dim_slot)\n",
    "\n",
    "    def forward(self, x, slots, t):\n",
    "        time_embedding = self.time_embed[t]\n",
    "        x = self.model(x, slots, time_embedding)\n",
    "        return x\n",
    "    \n",
    "    def time_embedding(self):\n",
    "        emb_arr = 2*torch.stack((torch.arange(self.dim_time//2), torch.arange(self.dim_time//2))).permute(1, 0).reshape(-1)\n",
    "        emb = torch.meshgrid(torch.arange(self.diffusion_time), emb_arr)\n",
    "        emb = emb[0]/(10000**(emb[1]/self.dim_time))\n",
    "        emb[:, ::2] = torch.sin(emb[:, ::2])\n",
    "        emb[:, 1::2] = torch.cos(emb[:, 1::2])\n",
    "\n",
    "        return emb\n",
    "\n",
    "class SlotDiffusion(torch.nn.Module):\n",
    "    def __init__(self, param: HyperParameters, device=device):\n",
    "        super(SlotDiffusion, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.param = param\n",
    "        self.encoder = Encoder(param.dim_input, param.shift, param.num_resblock, device=device)\n",
    "        self.slot_attention = SlotAttention(param.dim_input,\n",
    "                                            param.dim_slot,\n",
    "                                            param.dim_projected,\n",
    "                                            param.dim_mlp_slot,\n",
    "                                            param.num_slot,\n",
    "                                            param.num_iter_slot,\n",
    "                                            param.epsilon,\n",
    "                                            device=device)\n",
    "        \n",
    "        self.vae = VAE()\n",
    "        self.vae.load_state_dict(torch.load(addr.vae_checkpoint))\n",
    "        for p in self.vae.parameters():         # Freezing vae\n",
    "            p.requires_grad = False\n",
    "\n",
    "        self.register_buffer('var', self.var_schedule())\n",
    "\n",
    "        self.diffusion_decoder = LatentDefusionDecoder(dim_time = param.dim_time,\n",
    "                                                       diffusion_time = param.diffusion_time,\n",
    "                                                       num_channel = param.num_channel,\n",
    "                                                       num_repeat = param.num_repeat,\n",
    "                                                       dim_slot = param.dim_slot,\n",
    "                                                       dim_head = param.dim_head)\n",
    "\n",
    "    def forward(self, x, generate=False, slot_only = False, attn = False):\n",
    "        x_encoded = self.encoder(x)\n",
    "        if attn:\n",
    "            slots, attn_map = self.slot_attention(x_encoded, ret_attn = attn)\n",
    "        else:\n",
    "            slots = self.slot_attention(x_encoded)\n",
    "\n",
    "        if attn:\n",
    "            return attn_map\n",
    "\n",
    "        if slot_only:\n",
    "            return slots\n",
    "\n",
    "        if generate:\n",
    "            img = self.generate(slots)\n",
    "            return img\n",
    "\n",
    "        else:\n",
    "            vae_token = self.vae.encode(x)\n",
    "\n",
    "            noise = torch.randn(vae_token.shape).to(self.device)\n",
    "            t = torch.tensor([np.random.randint(self.param.diffusion_time) for _ in range(x.shape[0])], dtype=torch.int64)\n",
    "            alpha = self.var[2][t].reshape(-1, 1, 1, 1)\n",
    "            x_noised = torch.sqrt(1-alpha)*noise + torch.sqrt(alpha)*vae_token\n",
    "\n",
    "            pred_noise = self.diffusion_decoder(x_noised, slots, t)\n",
    "\n",
    "            return noise, pred_noise\n",
    "\n",
    "    def var_schedule(self):\n",
    "        beta = torch.arange(self.param.beta1, self.param.betaT, (self.param.betaT - self.param.beta1)/(self.param.diffusion_time-1))\n",
    "        alpha = 1-beta\n",
    "        alpha_bar = torch.cumprod(alpha, dim=0)\n",
    "        return torch.stack((beta, alpha, alpha_bar))\n",
    "\n",
    "    def generate(self, slots):\n",
    "        x = torch.randn((slots.shape[0], 3, 32, 32), device=self.device)\n",
    "        for t in range(self.param.diffusion_time, 0, -1):\n",
    "            z = torch.randn((slots.shape[0], 3, 32, 32), device=self.device) if t == 1 else 0\n",
    "            noise_pred = self.diffusion_decoder(x, slots, t-1)\n",
    "            x = x - noise_pred*(1-self.var[1][t-1])/torch.sqrt(1-self.var[2][t-1])\n",
    "            x = x/torch.sqrt(self.var[1][t-1]) + torch.sqrt(self.var[0][t-1])*z\n",
    "        return self.vae.decode(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0021cb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T15:28:56.794905Z",
     "iopub.status.busy": "2024-05-06T15:28:56.794631Z",
     "iopub.status.idle": "2024-05-06T15:28:56.900175Z",
     "shell.execute_reply": "2024-05-06T15:28:56.899406Z"
    },
    "papermill": {
     "duration": 0.114565,
     "end_time": "2024-05-06T15:28:56.902068",
     "exception": false,
     "start_time": "2024-05-06T15:28:56.787503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Metric\n",
    "def ARI(original_mask, predicted_mask, transform, total = False):\n",
    "    max_cat = data.dataset_val_with_mask.num_category\n",
    "    num_slot = predicted_mask.shape[1]\n",
    "\n",
    "    # Flattening and Reshaping to get masks of shape (Batch Size, H*W)\n",
    "    orig_mask = torch.flatten(original_mask, start_dim=1, end_dim=2)\n",
    "    pred_mask = torch.flatten(torch.argmax(transform(predicted_mask), dim=1), start_dim=1, end_dim=2)\n",
    "\n",
    "    # One Hot Encoding\n",
    "    pred_mask_oh = torch.nn.functional.one_hot(pred_mask, num_classes=num_slot).to(torch.float)\n",
    "    if total:\n",
    "        orig_mask_oh = torch.nn.functional.one_hot(orig_mask, num_classes=max_cat)[:, :, :].to(torch.float)       # Removing Background\n",
    "    else:\n",
    "        orig_mask_oh = torch.nn.functional.one_hot(orig_mask, num_classes=max_cat)[:, :, 1:].to(torch.float)       # Removing Background\n",
    "\n",
    "    # Number of non Background Points\n",
    "    n_points = torch.count_nonzero(orig_mask_oh)\n",
    "\n",
    "    # Calculating number of objects in common\n",
    "    nij = torch.bmm(orig_mask_oh.permute(0, 2, 1), pred_mask_oh)\n",
    "    ai = torch.sum(nij, dim=1)\n",
    "    bj = torch.sum(nij, dim=2)\n",
    "\n",
    "    # Calculating ARI\n",
    "    rindex = torch.sum(nij*(nij-1), dim=(1, 2))\n",
    "    aindex = torch.sum(ai*(ai-1), dim=1)\n",
    "    bindex = torch.sum(bj*(bj-1), dim=1)\n",
    "    expected_rindex = aindex*bindex / (n_points*(n_points-1))\n",
    "    max_rindex = (aindex + bindex)/2\n",
    "\n",
    "    return torch.mean((rindex - expected_rindex)/(max_rindex - expected_rindex)).item()\n",
    "\n",
    "def display(addr):\n",
    "    img = mpimg.imread(addr)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Learning Model\n",
    "class LearnModel:\n",
    "    def __init__(self, model: torch.nn.Module, model_addr, data=data, param=param, device=device):\n",
    "        '''\n",
    "        Train, Evaluate and Predict\n",
    "        '''\n",
    "        \n",
    "        self.data = data\n",
    "        self.param = param\n",
    "        self.device = device\n",
    "        self.model = model.to(device)\n",
    "        self.model_addr = model_addr\n",
    "\n",
    "        # Addresses\n",
    "        self.loss_addr = os.path.join(self.model_addr, 'loss.npz')\n",
    "        self.epoch_addr = lambda epoch: os.path.join(self.model_addr, f'model/{epoch}.pth')\n",
    "        self.scheduler_addr = lambda epoch: os.path.join(self.model_addr, f'scheduler/{epoch}.pth')\n",
    "        self.ari_addr = os.path.join(model_addr, \"ARI.txt\")\n",
    "        self.slot_addr = os.path.join(model_addr, \"slots.npz\")\n",
    "        self.img_addr = os.path.join(model_addr, \"gen_img\")\n",
    "        self.vis_addr = os.path.join(model_addr, \"visualize\")\n",
    "        addr.create_dir([os.path.join(self.model_addr, 'model'),\n",
    "                         os.path.join(self.model_addr, 'scheduler'),\n",
    "                         self.img_addr,\n",
    "                         self.vis_addr])\n",
    "\n",
    "    def train(self, epoch_log = True, batch_log = True, overwrite = False):\n",
    "        optimizer = torch.optim.Adam(params=self.model.parameters(), lr=self.param.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda = self.param.lr_schedule)\n",
    "        loss_fn = torch.nn.MSELoss().to(device)\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Loss arr\n",
    "        if os.path.exists(self.loss_addr):\n",
    "            loss_arr = np.load(self.loss_addr)\n",
    "            train_loss_arr = list(loss_arr['train'])\n",
    "            val_loss_arr = list(loss_arr['val'])\n",
    "        else:\n",
    "            train_loss_arr = []\n",
    "            val_loss_arr = []\n",
    "\n",
    "        if overwrite:\n",
    "            addr.clean([self.model_addr])\n",
    "        \n",
    "        for epoch in range(self.param.num_epoch):\n",
    "            epoch_addr = self.epoch_addr(epoch)\n",
    "            scheduler_addr = self.scheduler_addr(epoch)\n",
    "\n",
    "            # Loading Model if present\n",
    "            if os.path.exists(epoch_addr) and os.path.exists(scheduler_addr):\n",
    "                self.model.load_state_dict(torch.load(epoch_addr), strict=False)\n",
    "                scheduler.load_state_dict(torch.load(scheduler_addr))\n",
    "                print(f\"Loaded model and scheduler at epoch {epoch}\")\n",
    "                continue\n",
    "\n",
    "            # Training Model\n",
    "            train_loss = self.train_epoch(optimizer, scheduler, loss_fn, batch_log=batch_log)\n",
    "            if epoch_log:\n",
    "                print(f'Epoch: {epoch}\\tTrain Loss: {train_loss}\\tTime: {time.time()-start_time}')\n",
    "\n",
    "            # Validating Model\n",
    "            val_loss = self.validate_epoch(loss_fn, self.data.loader_val_without_mask, batch_log=batch_log)\n",
    "            if epoch_log:\n",
    "                print(f'Epoch: {epoch}\\tVal Loss: {val_loss}\\tTime: {time.time()-start_time}')\n",
    "\n",
    "            # Saving data\n",
    "            train_loss_arr.append(train_loss)\n",
    "            val_loss_arr.append(val_loss)\n",
    "            np.savez_compressed(self.loss_addr, train=np.array(train_loss_arr), val=np.array(val_loss_arr))     # Saving Loss Array\n",
    "            torch.save(self.model.state_dict(), epoch_addr)     # Saving Model\n",
    "            torch.save(scheduler.state_dict(), scheduler_addr)  # Saving Scheduler\n",
    "\n",
    "            # Printing blank line between each epoch in Log\n",
    "            if epoch_log:\n",
    "                print()\n",
    "        \n",
    "    def train_epoch(self, optimizer, scheduler, loss_fn, batch_log):\n",
    "        '''\n",
    "        Trains model for one epoch\n",
    "        '''\n",
    "        epoch_loss = 0\n",
    "        batch_ct = 0\n",
    "        dataloader = self.data.loader_train_without_mask\n",
    "        start_time = time.time()\n",
    "\n",
    "        self.model.train()          # Set Model to train Mode\n",
    "\n",
    "        for data in dataloader:\n",
    "            # Copying data to cuda\n",
    "            data = data.to(device)\n",
    "\n",
    "            # Forward Propagation\n",
    "            recon_img, img, mask, slots = self.model(data)\n",
    "\n",
    "            # Computing Loss\n",
    "            loss = loss_fn(data, recon_img)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # Back Propagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.param.grad_clip)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Update batch count\n",
    "            batch_ct += 1\n",
    "\n",
    "            if batch_log and batch_ct%1 == 0:\n",
    "                print(f\"\\tBatch {batch_ct}\\tLoss: {epoch_loss/batch_ct}\\tTime: {time.time()-start_time}\")\n",
    "\n",
    "        return epoch_loss/batch_ct\n",
    "    \n",
    "    def validate_epoch(self, loss_fn, dataloader, batch_log):\n",
    "        '''\n",
    "        Calculates Loss on data in given dataloader\n",
    "        '''\n",
    "        epoch_loss = 0\n",
    "        batch_ct = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        self.model.eval()           # Set Model to eval mode\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in dataloader:\n",
    "                # Copying data to cuda\n",
    "                data = data.to(device)\n",
    "\n",
    "                # Forward Propagation\n",
    "                recon_img, img, mask, slots = self.model(data)\n",
    "\n",
    "                # Computing Loss\n",
    "                loss = loss_fn(data, recon_img)\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                # Update batch count\n",
    "                batch_ct += 1\n",
    "\n",
    "                if batch_log and batch_ct%125 == 0:\n",
    "                    print(f\"\\tBatch {batch_ct}\\tLoss: {epoch_loss/batch_ct}\\tTime: {time.time()-start_time}\")\n",
    "\n",
    "        return epoch_loss/batch_ct\n",
    "\n",
    "    def plot_loss(self, addr = None):\n",
    "        '''\n",
    "        Plots Loss vs number of epochs\n",
    "        '''\n",
    "        if not os.path.exists(self.loss_addr):\n",
    "            raise Exception(\"No Loss Array\")\n",
    "        loss_arr = np.load(self.loss_addr)\n",
    "        train_arr, val_arr = loss_arr['train'], loss_arr['val']\n",
    "        num_epoch = train_arr.shape[0]\n",
    "        x_arr = np.linspace(1, num_epoch, num_epoch)\n",
    "\n",
    "        if addr is None:\n",
    "            addr = os.path.join(self.model_addr, 'loss_curve')\n",
    "\n",
    "        plt.title(\"Loss Curve\")\n",
    "        plt.xlabel(\"Number of Epochs\")\n",
    "        plt.ylabel(\"MSE Loss\")\n",
    "        plt.plot(x_arr, train_arr, label='Train')\n",
    "        plt.plot(x_arr, val_arr, label='Val')\n",
    "        plt.legend()\n",
    "        plt.savefig(addr)\n",
    "\n",
    "    def best_model(self):\n",
    "        '''\n",
    "        Returns Best Model as well as changes self.model in place to best model\n",
    "        '''\n",
    "        if not os.path.exists(self.loss_addr):\n",
    "            raise Exception(\"No Loss Array\")\n",
    "        loss_arr = np.load(self.loss_addr)\n",
    "        best_epoch = np.argmin(loss_arr['val'])\n",
    "        print(best_epoch)\n",
    "        self.model.load_state_dict(torch.load(self.epoch_addr(best_epoch)), strict=False)\n",
    "        return self.model\n",
    "    \n",
    "    def ARI_score(self, dataloader = None, log=True, total=False):\n",
    "        '''\n",
    "        Calculates ARI score for given dataloader (default validation dataset)\n",
    "        '''\n",
    "        self.model.eval()       # Set Model to eval mode\n",
    "        ari_score = 0\n",
    "        batch_ct = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        transform = None\n",
    "\n",
    "        if dataloader is None:\n",
    "            dataloader = self.data.loader_val_with_mask\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in dataloader:\n",
    "                # Loading Data\n",
    "                img_orig, mask_orig = data['img'].to(device), data['mask'].to(device)\n",
    "\n",
    "                # Forward Propagation\n",
    "                recon_img, img, mask_pred, slots = self.model(img_orig)\n",
    "\n",
    "                # Calculating ARI score\n",
    "                if transform is None:\n",
    "                    transform = torchvision.transforms.Resize(mask_orig.shape[1:], antialias=False)\n",
    "                ari_score += ARI(mask_orig, mask_pred, transform, total=total)\n",
    "                batch_ct += 1\n",
    "\n",
    "                # Log\n",
    "                if log and batch_ct%2 == 0:\n",
    "                    print(f\"Batch: {batch_ct}\\tARI score: {ari_score/batch_ct}\\tTime: {time.time()-start_time}\")\n",
    "\n",
    "        with open(self.ari_addr, mode='w') as file:\n",
    "            file.write(f\"ARI Score: {ari_score/batch_ct}\\n\")\n",
    "\n",
    "    def _kmean_slot(self, log):\n",
    "        '''\n",
    "        Use scikit Kmean to cluster slots\n",
    "        '''\n",
    "        batch_ct = 0\n",
    "        start_time = time.time()\n",
    "        dataloader = self.data.loader_train_without_mask\n",
    "\n",
    "        self.model.eval()           # Set Model to eval mode\n",
    "        slot_arr = torch.tensor([], device=self.device)\n",
    "\n",
    "        # Concatenating all slots\n",
    "        with torch.no_grad():\n",
    "            for data in dataloader:\n",
    "                # Copying data to cuda\n",
    "                data = data.to(device)\n",
    "\n",
    "                # Forward Propagation\n",
    "                slots = self.model(data, slot_only = True)\n",
    "\n",
    "                # Updating slot_arr\n",
    "                slot_arr = torch.concat((slot_arr, slots.reshape(-1, self.param.dim_slot)))\n",
    "\n",
    "                # Update batch count\n",
    "                batch_ct += 1\n",
    "\n",
    "                if log and batch_ct%125 == 0:\n",
    "                    print(f\"Computed Slot for Batch {batch_ct}\\tNumSlot: {slot_arr.shape}\\tTime: {time.time()-start_time}\")\n",
    "\n",
    "        # K-Mean Cluster\n",
    "        slot_arr = slot_arr.to(\"cpu\").detach().numpy()\n",
    "        kmean = KMeans(n_clusters=self.param.num_slot, n_init='auto', random_state=random_seed)\n",
    "        kmean.fit(slot_arr)\n",
    "        label = kmean.labels_\n",
    "        np.savez_compressed(self.slot_addr, slot=slot_arr, label=label)\n",
    "\n",
    "    def _sample_slot(self, slot_dict, slot_arr, batch_size):\n",
    "        '''\n",
    "        Randomly Samples slot from each cluster of kmean\n",
    "        '''\n",
    "        batch_slots = []\n",
    "        for _ in range(batch_size):\n",
    "            slots = []\n",
    "            for val in slot_dict:\n",
    "                slots.append(slot_arr[np.random.choice(slot_dict[val])])\n",
    "            batch_slots.append(np.stack(slots))\n",
    "        return np.stack(batch_slots)\n",
    "\n",
    "    def slot_lib(self, overwrite = False, log=True):\n",
    "        '''\n",
    "        Creates a slot library and generates images from it\n",
    "        '''\n",
    "        # Checking if trained model of kmean already present\n",
    "        if overwrite or not os.path.exists(self.slot_addr):\n",
    "            self._kmean_slot(log=log)\n",
    "        saved_arr = np.load(self.slot_addr)\n",
    "        slot_arr = saved_arr['slot']\n",
    "        label = saved_arr['label']\n",
    "        print(\"Loaded slot array and labels\")\n",
    "\n",
    "        # Storing slots labelwise\n",
    "        unique_values = np.unique(label)\n",
    "        slot_dict = {}\n",
    "        for val in unique_values:\n",
    "            slot_dict[val] = np.argwhere(label == val).flatten()\n",
    "\n",
    "        # Generating images via Random Slot Sampling\n",
    "        with torch.no_grad():\n",
    "            num_generate = len(self.data.dataset_val_without_mask)\n",
    "            ct_img = 0\n",
    "            for i in range(0, num_generate, self.param.batch_size):\n",
    "                batch_size = min(num_generate-i, self.param.batch_size)\n",
    "                generated_slots = torch.tensor(self._sample_slot(slot_dict, slot_arr, batch_size), dtype=torch.float32, device=self.device)\n",
    "                generated_img, _, _, _ = self.model.decoder(generated_slots)\n",
    "                for img in generated_img:\n",
    "                    torchvision.utils.save_image(img, os.path.join(self.img_addr, f'{ct_img}.png'))\n",
    "                    ct_img += 1\n",
    "\n",
    "    def visualize(self):\n",
    "        for data in self.data.loader_train_without_mask:\n",
    "            with torch.no_grad():\n",
    "                recon_img, img, mask, slots = self.model(data.to(device))\n",
    "                mask_oh = torch.nn.functional.one_hot(torch.argmax(mask, dim=1), self.param.num_slot).permute(0, 3, 1, 2)\n",
    "\n",
    "            for i in range(data.shape[0]):\n",
    "                img_path = os.path.join(self.vis_addr, f'{i}')\n",
    "                addr.create_dir([img_path])\n",
    "                torchvision.utils.save_image(data[i], os.path.join(img_path, 'orig.png'))\n",
    "                torchvision.utils.save_image(recon_img[i], os.path.join(img_path, 'regen.png'))\n",
    "                for slot_num in range(img.shape[1]):\n",
    "                    torchvision.utils.save_image(img[i, slot_num], os.path.join(img_path, f'img{slot_num}.png'))\n",
    "                    torchvision.utils.save_image(mask_oh[i, slot_num]*img[i, slot_num], os.path.join(img_path, f'threshold_img{slot_num}.png'))\n",
    "            break     \n",
    "\n",
    "    def attn_map(self, show_ct = 2):\n",
    "        with torch.no_grad():\n",
    "            for data in self.data.loader_val_with_mask:\n",
    "                img_orig, mask_orig = data['img'].to(device), data['mask']\n",
    "                attn = self.model(img_orig, attn = True)\n",
    "                B, T, N, K = attn.shape\n",
    "                dim = math.isqrt(N)\n",
    "                attn = attn.reshape(B, T, dim, dim, K).permute(0, 1, 4, 2, 3)\n",
    "                for i in range(img_orig.shape[0]):\n",
    "                    if show_ct <= 0:\n",
    "                        return\n",
    "                    torchvision.utils.save_image(img_orig[i], os.path.join(addr.temp, 'orig.png'))\n",
    "                    display(os.path.join(addr.temp, 'orig.png'))\n",
    "                    plt.figure(figsize=(15, 6))\n",
    "                    for t in range(T):\n",
    "                        for j in range(K):\n",
    "                            torchvision.utils.save_image(attn[i][t][j], os.path.join(addr.temp, 'pred.png'))\n",
    "                            # display(os.path.join(addr.temp, 'pred.png'))\n",
    "                            plt.subplot(T, K, t*K+j+1)\n",
    "                            img = mpimg.imread(os.path.join(addr.temp, 'pred.png'))\n",
    "                            plt.imshow(img)\n",
    "                            plt.axis('off')\n",
    "                    show_ct -= 1\n",
    "                    plt.show()\n",
    "\n",
    "# Learning Model\n",
    "class LearnModelDiff:\n",
    "    def __init__(self, model: torch.nn.Module, model_addr, data=data, param=param, device=device):\n",
    "        '''\n",
    "        Train, Evaluate and Predict\n",
    "        '''\n",
    "        \n",
    "        self.data = data\n",
    "        self.param = param\n",
    "        self.device = device\n",
    "        self.model = model.to(device)\n",
    "        self.model_addr = model_addr\n",
    "\n",
    "        # Addresses\n",
    "        self.loss_addr = os.path.join(self.model_addr, 'loss.npz')\n",
    "        self.epoch_addr = lambda epoch: os.path.join(self.model_addr, f'model/{epoch}.pth')\n",
    "        self.scheduler_addr = lambda epoch: os.path.join(self.model_addr, f'scheduler/{epoch}.pth')\n",
    "        self.ari_addr = os.path.join(model_addr, \"ARI.txt\")\n",
    "        self.slot_addr = os.path.join(model_addr, \"slots.npz\")\n",
    "        self.img_addr = os.path.join(model_addr, \"gen_img\")\n",
    "        self.vis_addr = os.path.join(model_addr, \"visualize\")\n",
    "        addr.create_dir([os.path.join(self.model_addr, 'model'),\n",
    "                         os.path.join(self.model_addr, 'scheduler'),\n",
    "                         self.img_addr,\n",
    "                         self.vis_addr])\n",
    "\n",
    "    def train(self, epoch_log = True, batch_log = True, overwrite = False):\n",
    "        lr_dict = [\n",
    "            {'params': self.model.encoder.parameters(), 'lr': self.param.slot_lr},\n",
    "            {'params': self.model.slot_attention.parameters(), 'lr': self.param.slot_lr},\n",
    "            {'params': self.model.diffusion_decoder.parameters()}\n",
    "        ]\n",
    "        optimizer = torch.optim.Adam(params=lr_dict, lr=self.param.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "            optimizer, \n",
    "            lr_lambda = [self.param.lr_schedule, self.param.lr_schedule, self.param.lr_schedule]\n",
    "        )\n",
    "        loss_fn = torch.nn.MSELoss().to(device)\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Loss arr\n",
    "        if os.path.exists(self.loss_addr):\n",
    "            loss_arr = np.load(self.loss_addr)\n",
    "            train_loss_arr = list(loss_arr['train'])\n",
    "            val_loss_arr = list(loss_arr['val'])\n",
    "        else:\n",
    "            train_loss_arr = []\n",
    "            val_loss_arr = []\n",
    "\n",
    "        if overwrite:\n",
    "            addr.clean([self.model_addr])\n",
    "        \n",
    "        for epoch in range(self.param.num_epoch):\n",
    "            epoch_addr = self.epoch_addr(epoch)\n",
    "            scheduler_addr = self.scheduler_addr(epoch)\n",
    "\n",
    "            # Loading Model if present\n",
    "            if os.path.exists(epoch_addr) and os.path.exists(scheduler_addr):\n",
    "                self.model.load_state_dict(torch.load(epoch_addr), strict=False)\n",
    "                scheduler.load_state_dict(torch.load(scheduler_addr))\n",
    "                print(f\"Loaded model and scheduler at epoch {epoch}\")\n",
    "                continue\n",
    "\n",
    "            # Training Model\n",
    "            train_loss = self.train_epoch(optimizer, scheduler, loss_fn, batch_log=batch_log)\n",
    "            if epoch_log:\n",
    "                print(f'Epoch: {epoch}\\tTrain Loss: {train_loss}\\tTime: {time.time()-start_time}')\n",
    "\n",
    "            # Validating Model\n",
    "            val_loss = self.validate_epoch(loss_fn, self.data.loader_val_without_mask, batch_log=batch_log)\n",
    "            if epoch_log:\n",
    "                print(f'Epoch: {epoch}\\tVal Loss: {val_loss}\\tTime: {time.time()-start_time}')\n",
    "\n",
    "            # Saving data\n",
    "            train_loss_arr.append(train_loss)\n",
    "            val_loss_arr.append(val_loss)\n",
    "            np.savez_compressed(self.loss_addr, train=np.array(train_loss_arr), val=np.array(val_loss_arr))     # Saving Loss Array\n",
    "            torch.save(self.model.state_dict(), epoch_addr)     # Saving Model\n",
    "            torch.save(scheduler.state_dict(), scheduler_addr)  # Saving Scheduler\n",
    "\n",
    "            # Printing blank line between each epoch in Log\n",
    "            if epoch_log:\n",
    "                print()\n",
    "        \n",
    "    def train_epoch(self, optimizer, scheduler, loss_fn, batch_log):\n",
    "        '''\n",
    "        Trains model for one epoch\n",
    "        '''\n",
    "        epoch_loss = 0\n",
    "        batch_ct = 0\n",
    "        dataloader = self.data.loader_train_without_mask\n",
    "        start_time = time.time()\n",
    "\n",
    "        self.model.train()          # Set Model to train Mode\n",
    "\n",
    "        for data in dataloader:\n",
    "            # Copying data to cuda\n",
    "            data = data.to(device)\n",
    "\n",
    "            # Forward Propagation\n",
    "            noise, pred_noise = self.model(data)\n",
    "\n",
    "            # Computing Loss\n",
    "            loss = loss_fn(noise, pred_noise)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # Back Propagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.param.grad_clip)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Update batch count\n",
    "            batch_ct += 1\n",
    "\n",
    "            if batch_log and batch_ct%50 == 0:\n",
    "                print(f\"\\tBatch {batch_ct}\\tLoss: {epoch_loss/batch_ct}\\tTime: {time.time()-start_time}\")\n",
    "\n",
    "        return epoch_loss/batch_ct\n",
    "    \n",
    "    def validate_epoch(self, loss_fn, dataloader, batch_log):\n",
    "        '''\n",
    "        Calculates Loss on data in given dataloader\n",
    "        '''\n",
    "        epoch_loss = 0\n",
    "        batch_ct = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        self.model.eval()           # Set Model to eval mode\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in dataloader:\n",
    "                # Copying data to cuda\n",
    "                data = data.to(device)\n",
    "\n",
    "                # Forward Propagation\n",
    "                noise, pred_noise = self.model(data)\n",
    "\n",
    "                # Computing Loss\n",
    "                loss = loss_fn(noise, pred_noise)\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                # Update batch count\n",
    "                batch_ct += 1\n",
    "\n",
    "                if batch_log and batch_ct%125 == 0:\n",
    "                    print(f\"\\tBatch {batch_ct}\\tLoss: {epoch_loss/batch_ct}\\tTime: {time.time()-start_time}\")\n",
    "\n",
    "        return epoch_loss/batch_ct\n",
    "\n",
    "    def plot_loss(self, addr = None):\n",
    "        '''\n",
    "        Plots Loss vs number of epochs\n",
    "        '''\n",
    "        if not os.path.exists(self.loss_addr):\n",
    "            raise Exception(\"No Loss Array\")\n",
    "        loss_arr = np.load(self.loss_addr)\n",
    "        train_arr, val_arr = loss_arr['train'], loss_arr['val']\n",
    "        num_epoch = train_arr.shape[0]\n",
    "        x_arr = np.linspace(1, num_epoch, num_epoch)\n",
    "\n",
    "        if addr is None:\n",
    "            addr = os.path.join(self.model_addr, 'loss_curve')\n",
    "\n",
    "        plt.title(\"Loss Curve\")\n",
    "        plt.xlabel(\"Number of Epochs\")\n",
    "        plt.ylabel(\"MSE Loss\")\n",
    "        plt.plot(x_arr, train_arr, label='Train')\n",
    "        plt.plot(x_arr, val_arr, label='Val')\n",
    "        plt.legend()\n",
    "        plt.savefig(addr)\n",
    "\n",
    "    def best_model(self):\n",
    "        '''\n",
    "        Returns Best Model as well as changes self.model in place to best model\n",
    "        '''\n",
    "        if not os.path.exists(self.loss_addr):\n",
    "            raise Exception(\"No Loss Array\")\n",
    "        loss_arr = np.load(self.loss_addr)\n",
    "        best_epoch = np.argmin(loss_arr['val'])\n",
    "        self.model.load_state_dict(torch.load(self.epoch_addr(best_epoch)), strict=False)\n",
    "        return self.model\n",
    "\n",
    "    def _kmean_slot(self, log):\n",
    "        '''\n",
    "        Use scikit Kmean to cluster slots\n",
    "        '''\n",
    "        batch_ct = 0\n",
    "        start_time = time.time()\n",
    "        dataloader = self.data.loader_train_without_mask\n",
    "\n",
    "        self.model.eval()           # Set Model to eval mode\n",
    "        slot_arr = torch.tensor([], device=self.device)\n",
    "\n",
    "        # Concatenating all slots\n",
    "        with torch.no_grad():\n",
    "            for data in dataloader:\n",
    "                # Copying data to cuda\n",
    "                data = data.to(device)\n",
    "\n",
    "                # Forward Propagation\n",
    "                slots = self.model(data, slot_only = True)\n",
    "\n",
    "                # Updating slot_arr\n",
    "                slot_arr = torch.concat((slot_arr, slots.reshape(-1, self.param.dim_slot)))\n",
    "\n",
    "                # Update batch count\n",
    "                batch_ct += 1\n",
    "\n",
    "                if log and batch_ct%125 == 0:\n",
    "                    print(f\"Computed Slot for Batch {batch_ct}\\tNumSlot: {slot_arr.shape}\\tTime: {time.time()-start_time}\")\n",
    "\n",
    "        # K-Mean Cluster\n",
    "        slot_arr = slot_arr.to(\"cpu\").detach().numpy()\n",
    "        kmean = KMeans(n_clusters=self.param.num_slot, n_init='auto', random_state=random_seed)\n",
    "        kmean.fit(slot_arr)\n",
    "        label = kmean.labels_\n",
    "        np.savez_compressed(self.slot_addr, slot=slot_arr, label=label)\n",
    "\n",
    "    def _sample_slot(self, slot_dict, slot_arr, batch_size):\n",
    "        '''\n",
    "        Randomly Samples slot from each cluster of kmean\n",
    "        '''\n",
    "        batch_slots = []\n",
    "        for _ in range(batch_size):\n",
    "            slots = []\n",
    "            for val in slot_dict:\n",
    "                slots.append(slot_arr[np.random.choice(slot_dict[val])])\n",
    "            batch_slots.append(np.stack(slots))\n",
    "        return np.stack(batch_slots)\n",
    "\n",
    "    def slot_lib(self, overwrite = False, log=True, show_ct = 0):\n",
    "        '''\n",
    "        Creates a slot library and generates images from it\n",
    "        '''\n",
    "        # Checking if trained model of kmean already present\n",
    "        if overwrite or not os.path.exists(self.slot_addr):\n",
    "            self._kmean_slot(log=log)\n",
    "        saved_arr = np.load(self.slot_addr)\n",
    "        slot_arr = saved_arr['slot']\n",
    "        label = saved_arr['label']\n",
    "        print(\"Loaded slot array and labels\")\n",
    "\n",
    "        # Storing slots labelwise\n",
    "        unique_values = np.unique(label)\n",
    "        slot_dict = {}\n",
    "        for val in unique_values:\n",
    "            slot_dict[val] = np.argwhere(label == val).flatten()\n",
    "\n",
    "        # Generating images via Random Slot Sampling\n",
    "        with torch.no_grad():\n",
    "            num_generate = len(self.data.dataset_val_without_mask)\n",
    "            ct_img = 0\n",
    "            for i in range(0, num_generate, self.param.batch_size):\n",
    "                batch_size = min(num_generate-i, self.param.batch_size)\n",
    "                generated_slots = torch.tensor(self._sample_slot(slot_dict, slot_arr, batch_size), dtype=torch.float32, device=self.device)\n",
    "                generated_img = self.model.generate(generated_slots)\n",
    "                for img in generated_img:\n",
    "                    torchvision.utils.save_image(img, os.path.join(self.img_addr, f'{ct_img}.png'))\n",
    "                    if ct_img < show_ct:\n",
    "                        display(os.path.join(self.img_addr, f'{ct_img}.png'))\n",
    "                    ct_img += 1\n",
    "\n",
    "    def visualize(self, show=True):\n",
    "        for data in self.data.loader_train_without_mask:\n",
    "            with torch.no_grad():\n",
    "                gen_img = self.model(data.to(device), generate = True)\n",
    "\n",
    "            for i in range(data.shape[0]):\n",
    "                torchvision.utils.save_image(data[i], os.path.join(self.vis_addr, f'{i}_orig.png'))\n",
    "                torchvision.utils.save_image(gen_img[i], os.path.join(self.vis_addr, f'{i}_pred.png'))\n",
    "                if show:\n",
    "                    display(os.path.join(self.vis_addr, f'{i}_orig.png'))\n",
    "                    display(os.path.join(self.vis_addr, f'{i}_pred.png'))\n",
    "            break\n",
    "\n",
    "    def attn_map(self, show_ct = 2):\n",
    "        with torch.no_grad():\n",
    "            for data in self.data.loader_val_with_mask:\n",
    "                img_orig, mask_orig = data['img'].to(device), data['mask']\n",
    "                attn = self.model(img_orig, attn = True)\n",
    "                B, T, N, K = attn.shape\n",
    "                dim = math.isqrt(N)\n",
    "                attn = attn.reshape(B, T, dim, dim, K).permute(0, 1, 4, 2, 3)\n",
    "                for i in range(img_orig.shape[0]):\n",
    "                    if show_ct <= 0:\n",
    "                        return\n",
    "                    torchvision.utils.save_image(img_orig[i], os.path.join(addr.temp, 'orig.png'))\n",
    "                    display(os.path.join(addr.temp, 'orig.png'))\n",
    "                    plt.figure(figsize=(15, 6))\n",
    "                    for t in range(T):\n",
    "                        for j in range(K):\n",
    "                            torchvision.utils.save_image(attn[i][t][j], os.path.join(addr.temp, 'pred.png'))\n",
    "                            plt.subplot(T, K, t*K+j+1)\n",
    "                            img = mpimg.imread(os.path.join(addr.temp, 'pred.png'))\n",
    "                            plt.imshow(img)\n",
    "                            plt.axis('off')\n",
    "                    show_ct -= 1\n",
    "                    plt.show()\n",
    "\n",
    "    def ARI_score(self, dataloader = None, log=True, total = False):\n",
    "        '''\n",
    "        Calculates ARI score for given dataloader (default validation dataset)\n",
    "        '''\n",
    "        self.model.eval()       # Set Model to eval mode\n",
    "        ari_score = 0\n",
    "        batch_ct = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        transform = None\n",
    "\n",
    "        if dataloader is None:\n",
    "            dataloader = self.data.loader_val_with_mask\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in dataloader:\n",
    "                # Loading Data\n",
    "                img_orig, mask_orig = data['img'].to(device), data['mask'].to(device)\n",
    "\n",
    "                # Forward Propagation\n",
    "                attn_map = self.model(img_orig, attn = True)\n",
    "                attn_map = attn_map[:, 2, :, :]\n",
    "                B, N, K = attn_map.shape\n",
    "                dim = math.isqrt(N)\n",
    "                attn_map = attn_map.reshape(B, dim, dim, K).permute(0, 3, 1, 2)\n",
    "\n",
    "                # Calculating ARI score\n",
    "                if transform is None:\n",
    "                    transform = torchvision.transforms.Resize(mask_orig.shape[1:], antialias=False)\n",
    "                ari_score += ARI(mask_orig, attn_map, transform, total=total)\n",
    "                batch_ct += 1\n",
    "\n",
    "                # Log\n",
    "                if log and batch_ct%1 == 0:\n",
    "                    print(f\"Batch: {batch_ct}\\tARI score: {ari_score/batch_ct}\\tTime: {time.time()-start_time}\")\n",
    "\n",
    "        with open(self.ari_addr, mode='w') as file:\n",
    "            file.write(f\"ARI Score: {ari_score/batch_ct}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48a79e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T15:28:56.913856Z",
     "iopub.status.busy": "2024-05-06T15:28:56.913588Z",
     "iopub.status.idle": "2024-05-06T15:28:57.288998Z",
     "shell.execute_reply": "2024-05-06T15:28:57.288153Z"
    },
    "papermill": {
     "duration": 0.383534,
     "end_time": "2024-05-06T15:28:57.290989",
     "exception": false,
     "start_time": "2024-05-06T15:28:56.907455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ObjectDiscovery(param, device=device).to(device)\n",
    "learner = LearnModel(model, addr.slot_attention)\n",
    "# learner.param.create_report(learner.model_addr)\n",
    "# learner.train()\n",
    "# learner.plot_loss()\n",
    "# learner.best_model()\n",
    "learner.model.load_state_dict(torch.load(addr.slot_checkpoint), strict=False)\n",
    "learner.ARI_score(total=True)\n",
    "# learner.slot_lib()\n",
    "# learner.visualize()\n",
    "# learner.attn_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003c8d8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T15:28:57.303227Z",
     "iopub.status.busy": "2024-05-06T15:28:57.302912Z",
     "iopub.status.idle": "2024-05-07T01:54:04.357802Z",
     "shell.execute_reply": "2024-05-07T01:54:04.356673Z"
    },
    "papermill": {
     "duration": 37507.063358,
     "end_time": "2024-05-07T01:54:04.359946",
     "exception": false,
     "start_time": "2024-05-06T15:28:57.296588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_diff = SlotDiffusion(param).to(device)\n",
    "learner_diff = LearnModelDiff(model_diff, addr.slot_diffusion)\n",
    "# learner_diff.param.create_report(learner_diff.model_addr)\n",
    "# learner_diff.model.encoder.load_state_dict(learner.model.encoder.state_dict(), strict=False)        # Pretrained weights from previous part\n",
    "# learner_diff.model.slot_attention.load_state_dict(learner.model.slot_attention.state_dict(), strict=False)\n",
    "# learner_diff.train()\n",
    "# learner_diff.plot_loss()\n",
    "learner_diff.best_model()\n",
    "# learner_diff.model.load_state_dict(torch.load(addr.diff_checkpoint), strict=False)\n",
    "# learner_diff.ARI_score(total=True)\n",
    "# learner_diff.slot_lib(show_ct=4)\n",
    "# learner_diff.visualize()\n",
    "# learner_diff.attn_map()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4773120,
     "sourceId": 8329793,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30683,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 37536.868027,
   "end_time": "2024-05-07T01:54:07.181733",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-06T15:28:30.313706",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
